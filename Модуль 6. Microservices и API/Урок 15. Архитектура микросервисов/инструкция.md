## 1. Введение  
Переход от монолитной архитектуры к микросервисной выполняется для повышения масштабируемости, надежности и гибкости приложения. В монолитном приложении все компоненты (например, модуль пользователей, бизнес-логика, работа с данными) объединены в единый сервис, что упрощает начальную разработку, но со временем приводит к сложностям в поддержке и масштабировании. При росте команды или нагрузки монолит сложно быстро изменять: любое обновление требует перекомпоновки и развертывания всего приложения целиком. Кроме того, сбой в одной части монолита может вывести из строя все приложение.

 ([What are Microservices? - GeeksforGeeks](https://www.geeksforgeeks.org/microservices/?ref=next_article_top)) В микросервисной архитектуре приложение разделяется на несколько независимых сервисов, каждый из которых отвечает за свою зону ответственности. Например, **сервис аутентификации** будет заниматься только регистрацией и входом пользователей, а основной **сервис LostFoundService** — только логикой объявлений о пропаже и находке. Эти сервисы взаимодействуют друг с другом через четко определенные API. Благодаря такому разделению, каждый микросервис можно масштабировать и разворачивать отдельно, что упрощает развитие системы и локализацию ошибок. *На рисунке показано сравнение монолита (слева) и эквивалентной функциональности, разбитой на микросервисы (справа).* 

В исходном монолитном приложении “Lost & Found” (до рефакторинга) функциональность поиска/находки вещей и управление пользователями (аутентификация) были частью одного FastAPI-приложения. После перехода к микросервисной архитектуре мы получили два автономных сервиса: `AuthService` для работы с пользователями (регистрация, логин, выдача JWT-токенов) и `LostFoundService` для управления объявлениями о потерянных и найденных вещах. В качестве входной точки в систему используется API Gateway (на базе Nginx), через который клиентские запросы маршрутизируются к нужному сервису. Такая архитектура позволяет развивать сервисы независимо и обеспечивает лучшую изоляцию: изменения в `AuthService` не требуют разворачивать заново `LostFoundService`, и наоборот.

## 2. Разделение сервисов  
**Выделение AuthService.** Первым шагом монолит разделяется по доменам: выносится вся логика, связанная с пользователями и аутентификацией, в отдельный сервис `AuthService`. Для этого создается новая структура проекта (например, новая папка или репозиторий) для `AuthService` с собственным приложением FastAPI. В этот сервис переносится следующее: маршруты для регистрации и логина пользователей, модели пользователя и связанные схемы (Pydantic-модели), а также функциональность выдачи токенов доступа (JWT). 

Например, в монолите мог быть маршрут `/login`, принимающий имя пользователя и пароль, выполняющий проверку и возвращающий JWT-токен. Этот код теперь перемещается в `AuthService`. В `AuthService` создается свой модуль маршрутов, например `auth/routes.py`, со следующим содержимым: 

```python
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from . import models, schemas, security  # собственные модели, схемы, утилиты безопасности
from .database import get_db  # зависимость для получения сессии БД

router = APIRouter()

@router.post("/login", response_model=schemas.Token)
def login(form_data: schemas.LoginForm, db: Session = Depends(get_db)):
    user = models.User.authenticate(db, form_data.username, form_data.password)
    if not user:
        raise HTTPException(status_code=400, detail="Incorrect username or password")
    # Генерация JWT-токена для пользователя
    token = security.create_jwt_token({"sub": user.username})
    return {"access_token": token, "token_type": "bearer"}
```

В этом примере маршрут `login` теперь находится в `AuthService` и использует собственную функцию `create_jwt_token` для выдачи JWT. Аналогично, в `AuthService` можно реализовать маршрут `/register` для регистрации новых пользователей.

**Отделение базы данных для AuthService.** `AuthService` должен иметь собственное хранилище данных (например, отдельную базу Postgres для хранения пользователей и токенов/сессий, если они нужны). Это значит, что необходимо настроить подключение к базе данных и миграции. В `AuthService` добавляем модуль для работы с БД, например `auth/database.py`, который создает `SessionLocal` и `engine` SQLAlchemy для новой базы данных пользователей:

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from .config import settings

engine = create_engine(settings.database_url)
SessionLocal = sessionmaker(bind=engine)

# Зависимость для получения сессии в каждом запросе
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

Здесь `settings.database_url` – строка подключения к БД (например, PostgreSQL), которую мы возьмем из конфигурации окружения (об этом ниже). 

Для управления схемой БД в `AuthService` настраивается **Alembic** – инструмент миграций. Если в монолите уже использовался Alembic, для нового сервиса нужно инициализировать отдельную конфигурацию Alembic (обычно командой `alembic init` в каталоге AuthService). В файлах Alembic (`alembic.ini` и скрипте окружения `env.py`) настраиваем строку подключения к новой базе данных и указываем модели для автогенного создания таблиц. Например, в `auth/alembic/env.py` регистрируем модели пользователя:

```python
from auth import models
from auth.database import engine
target_metadata = models.Base.metadata  # Base из декларативных моделей пользователя

def run_migrations_online():
    # ...
    connectable = engine
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)
        # ...
```

Далее создаем первую миграцию для `AuthService` (например, `alembic revision --autogenerate -m "create users table"`), и выполняем `alembic upgrade head` для создания таблицы пользователей в новой базе данных.

**Настройка конфигурации (Pydantic Settings).** В новом сервисе важно изолировать конфигурацию. Используем Pydantic для управления настройками окружения. Например, в `auth/config.py`:

```python
from pydantic import BaseSettings

class Settings(BaseSettings):
    database_url: str  # URL подключения к базе AuthService
    jwt_secret: str    # секретный ключ для подписи JWT токенов
    jwt_algorithm: str = "HS256"
    token_expire_minutes: int = 60

    class Config:
        env_file = ".env"  # читать настройки из файла .env
        case_sensitive = True

settings = Settings()
```

Этот класс будет считывать переменные окружения (например, `DATABASE_URL`, `JWT_SECRET`) из файла `.env` или переменных среды Docker. Секретный ключ (`jwt_secret`) будет использоваться для подписи JWT токенов. Обратите внимание, что **тот же самый секретный ключ** должен использоваться и `LostFoundService` для проверки подписи токена (если используется симметричная подпись), либо нужно предусмотреть обмен открытым ключом, если применяется асимметричная криптография. 

После создания `AuthService` убедитесь, что он запускается автономно. У него должен быть свой `main.py` (или точка входа) с созданием приложения FastAPI и подключением маршрутов, например:

```python
from fastapi import FastAPI
from auth.routes import router as auth_router

app = FastAPI(title="AuthService API")
app.include_router(auth_router, prefix="/auth")
```

Здесь мы подключаем роутер `auth_router` с префиксом `/auth`. Это удобно, чтобы все пути аутентификации были сгруппированы (например, `/auth/login`, `/auth/register`). Title указывается для удобства, чтобы различать Swagger UI разных сервисов.

## 3. Обновление LostFoundService  
После выноса аутентификации, основной сервис `LostFoundService` необходимо очистить от старой логики, связанной с пользователями, и настроить его на использование нового сервиса авторизации. 

**Удаление встроенной аутентификации.** В кодовой базе `LostFoundService` убираются модели пользователей, эндпоинты для логина/регистрации и всё, что связано с проверкой паролей. Например, если в монолите был маршрут `/login` или зависимость `get_current_user` обращалась к базе данных пользователей, этот код либо удаляется, либо модифицируется. Больше не нужно хранить пароли или выдавать токены в `LostFoundService` – все это теперь делает `AuthService`. 

Также нужно проверить модели данных: если ранее, к примеру, в таблице объявлений хранилась ссылка на пользователя (foreign key), то `LostFoundService` может по-прежнему хранить идентификатор пользователя, создавшего объявление, но самих данных о пользователе (имени, email и пр.) у него больше нет. Эта информация при необходимости будет получаться от `AuthService` (либо передаваться в JWT). На данном этапе может потребоваться миграция в базе `LostFoundService` для удаления таблицы пользователей или полей, которые больше не нужны в монолите.

**Добавление JWT-защиты.** Теперь `LostFoundService` должен доверять токенам от `AuthService` и использовать их для аутентификации запросов. В FastAPI это обычно реализуется через зависимость OAuth2. В начале приложения `LostFoundService` настраиваем OAuth2-схему, используя класс `OAuth2PasswordBearer` из `fastapi.security`. Поскольку `AuthService` выдает токен, точка выдачи токена (`tokenUrl`) будет URL `AuthService`. Например:

```python
from fastapi.security import OAuth2PasswordBearer
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="http://auth_service:8000/auth/login")
```

Здесь мы указываем URL эндпоинта логина на сервисе аутентификации (предполагая, что `AuthService` внутри Docker-компоуза доступен по имени хоста `auth_service` на порту 8000). Этот объект `oauth2_scheme` позволяет FastAPI извлекать токен из заголовка `Authorization` запроса.

Далее определяем функцию-депенденси, которая будет вызываться перед защищенными эндпоинтами для валидации токена:

```python
from jose import JWTError, jwt  # библиотека python-jose для работы с JWT

SECRET_KEY = "SUPERSECRETJWTKEY"  # секрет должен совпадать с AuthService.settings.jwt_secret
ALGORITHM = "HS256"

def get_current_user(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: int = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid token")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
    return user_id  # или можно вернуть словарь с информацией о пользователе
```

Эта функция `get_current_user` будет декодировать JWT токен. Она использует тот же `SECRET_KEY` и алгоритм, что и `AuthService` при создании токена. Если токен недействителен или истек, выбрасывается `HTTPException` 401. В случае успеха из payload извлекается идентификатор пользователя (`sub`) – предполагается, что при генерации токена мы поместили в поле `sub` идентификатор или имя пользователя. 

Теперь можно защищать необходимые маршруты в `LostFoundService` с помощью зависимости. Например, если маршрут для создания нового объявления ранее не требовал токена, теперь сделаем его доступным только для авторизованных пользователей:

```python
from fastapi import Depends

@app.post("/items/")
def create_item(item: schemas.ItemCreate, user_id: int = Depends(get_current_user)):
    # теперь у нас есть идентификатор пользователя из токена
    # можно использовать user_id при сохранении объявления, связывая его с владельцем
    return services.create_item(item, owner_id=user_id)
```

Здесь `Depends(get_current_user)` гарантирует, что запрос без валидного JWT не пройдет, а `user_id` будет передан в функцию с идентификатором текущего пользователя. 

Стоит убедиться, что `LostFoundService` **знает секретный ключ JWT, используемый AuthService**. Самый простой способ – продублировать переменную окружения с секретом в настройках обоих сервисов. В боевых условиях лучше использовать централизованный сервис авторизации или общедоступный публичный ключ, но для учебного примера одинаковый `SECRET_KEY` на двух сервисах приемлем.

**Изменение зависимостей проекта.** Поскольку `LostFoundService` больше не управляет пользователями, можно обновить его требования (requirements). Например, может отпасть необходимость в библиотеке для хеширования паролей (`passlib`) или в модели пользователя. Зато может понадобиться библиотека для работы с JWT (например, `python-jose` или `PyJWT`) для проверки токенов. Убедитесь, что файл зависимостей `requirements.txt` или `pyproject.toml` скорректирован: убраны лишние пакеты и добавлены новые, нужные для JWT-валидации. Аналогично, для `AuthService` сформируйте свой набор зависимостей: ему, например, нужен `passlib` для хеширования паролей, `python-jose` для генерации JWT, Pydantic, FastAPI, SQLAlchemy, Alembic и др., тогда как `LostFoundService` может не требовать `passlib` вовсе. Разделение зависимостей улучшит изоляцию сервисов – каждый имеет только необходимое.

После этих изменений `LostFoundService` становится чище: он не знает ничего о паролях или сессиях, а лишь проверяет, что в запросе есть валидный токен и извлекает из него идентификатор пользователя для связывания с данными (например, отмечает, кто создал запись о пропаже вещи).

## 4. Контейнеризация и управление сервисами  
Чтобы развернуть новую архитектуру, нужно настроить контейнеризацию для каждого микросервиса и оркестрацию их запуска. Ранее монолитное приложение, возможно, запускалось одним Docker-контейнером (плюс контейнер базы данных). Теперь у нас два приложения, поэтому **`docker-compose.yml` разделяется на несколько сервисов**: `auth_service`, `lostfound_service`, отдельные базы данных для каждого (если используются разные БД), и контейнер API Gateway (Nginx). 

Пример структуры `docker-compose.yml` после разделения сервисов:

```yaml
version: '3.8'
services:
  auth_service:
    build: ./AuthService
    container_name: auth_service
    env_file: auth.env              # файл с переменными окружения для AuthService
    ports:
      - "8001:8000"                # порт AuthService (можно не экспонировать, если идет через Nginx)
    depends_on:
      - auth_db

  lostfound_service:
    build: ./LostFoundService
    container_name: lostfound_service
    env_file: lostfound.env         # файл с переменными окружения для LostFoundService
    ports:
      - "8002:8000"                # порт LostFoundService
    depends_on:
      - lostfound_db

  auth_db:
    image: postgres:15
    container_name: auth_db
    environment:
      - POSTGRES_USER=auth_user
      - POSTGRES_PASSWORD=auth_password
      - POSTGRES_DB=auth_db
    volumes:
      - auth_data:/var/lib/postgresql/data

  lostfound_db:
    image: postgres:15
    container_name: lostfound_db
    environment:
      - POSTGRES_USER=lf_user
      - POSTGRES_PASSWORD=lf_password
      - POSTGRES_DB=lostfound_db
    volumes:
      - lf_data:/var/lib/postgresql/data

  nginx:
    image: nginx:latest
    container_name: api_gateway
    ports:
      - "80:80"                    # внешний порт для входящих запросов
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - auth_service
      - lostfound_service

volumes:
  auth_data:
  lf_data:
```

В этом Compose-файле определены два сервисных контейнера приложения (`auth_service` и `lostfound_service`), их базы данных, и сервис `nginx` выполняющий роль API Gateway. Обратите внимание на использование разных файлов окружения (`auth.env` и `lostfound.env`) для передачи настроек в каждый сервис отдельно – это следует из принципа, что микросервисы не должны шарить глобальные настройки, каждый имеет свою конфигурацию (хотя некоторые значения, например URL-ы, могут дублироваться).

Контейнеры баз данных (`auth_db` и `lostfound_db`) созданы раздельно, чтобы каждый микросервис имел свою схему данных. В переменных окружения мы указали учетные данные и имя базы. Volume используются для сохранения данных между перезапусками. 

**Dockerfile для каждого сервиса.** Убедитесь, что у вас есть Dockerfile для `AuthService` и для `LostFoundService`. Они могут быть похожи (оба Python FastAPI приложения), например:

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . /app

# Установка зависимостей
RUN pip install -r requirements.txt

# Запуск приложения (например, через uvicorn)
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Каждый Dockerfile находится в папке соответствующего сервиса. В Compose мы используем `build: ./AuthService` и `build: ./LostFoundService` – это значит, что docker-compose найдет Dockerfile в указанных директориях и соберет образ.

При разделении сервисов важно убедиться, что они могут общаться друг с другом. В Docker Compose все контейнеры в одном проекте находятся в общей сети по умолчанию, и доступны по имени сервиса как хост. Например, из контейнера `lostfound_service` мы можем обратиться к `auth_service` по URL `http://auth_service:8000` (название сервиса становится DNS-именем). Это понадобится, если вдруг `LostFoundService` должен сделать внутренний запрос к `AuthService` (хотя в нашем случае достаточно того, что клиент сам ходит через gateway). Через Compose мы уже описали `depends_on`, указывая, что `auth_service` и `lostfound_service` должны стартовать после соответствующих БД, а Nginx после приложений.

**API Gateway (Nginx) контейнер.** Добавление Nginx-контейнера позволяет направлять внешние запросы на нужный сервис в зависимости от пути. Мы пробросили порт 80 контейнера Nginx наружу, так что пользователю достаточно обращаться по адресу одного сервера. Nginx-конфигурация хранится локально (например, `nginx.conf`) и монтируется в контейнер (в `docker-compose.yml` мы это указали). Рассмотрим настройку Nginx подробнее в следующем разделе.

## 5. Настройка API Gateway (Nginx)  
API Gateway с помощью Nginx будет выполнять обратное проксиирование (reverse proxy) запросов к соответствующим микросервисам. Мы разделили URL-префиксы: допустим, все запросы, начинающиеся с `/auth/`, должны направляться в сервис `AuthService`, а все запросы с `/api/` – в `LostFoundService`. Также нужно учесть, чтобы документация Swagger UI каждого сервиса работала корректно через gateway.

Пример минимальной конфигурации `nginx.conf`:

```nginx
events {
    worker_connections 1024;
}

http {
    # upstream не обязателен, можно обращаться по имени сервиса напрямую
    upstream auth_service { server auth_service:8000; }
    upstream lostfound_service { server lostfound_service:8000; }

    server {
        listen 80;
        server_name localhost;

        location /auth/ {
            proxy_pass http://auth_service:8000/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        location /api/ {
            proxy_pass http://lostfound_service:8000/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

В этом конфигурационном файле мы определили один сервер, слушающий порт 80. Директивы `location` распределяют запросы:  
- **`/auth/`**: все, что идет после `/auth/` проксируется на `auth_service:8000`. Обратите внимание на слэш в конце `proxy_pass`: `http://auth_service:8000/` – он важен, чтобы путь `/auth/route` заменялся на `/route` при отправке во внутренний сервис. Таким образом, внутренний сервис получит правильный путь.  
- **`/api/`**: аналогично проксируется на `lostfound_service:8000`. Предполагается, что все эндпоинты LostFoundService начинаются с `/api/` (или мы просто используем `/api/` как префикс для маршрутизации). Если в самом приложении `LostFoundService` пути не сгруппированы под `/api`, ничего страшного – префикс `/api` используется только на уровне gateway для отделения от `/auth`. Nginx убирает этот префикс при пересылке (за счет настроенного слэша в `proxy_pass`). Например, внешний запрос `GET /api/items/1` превратится во внутренний запрос `GET /items/1` к сервису `lostfound_service`.

Заголовки `proxy_set_header` нужны для передачи хоста и реального IP – это помогает для логирования и корректной работы некоторых функций (например, если сервисы смотрят на `request.host` или для формирования URL в документации). 

**Swagger UI через Gateway.** Без дополнительной настройки, если вы попытаетесь открыть Swagger UI, могут возникнуть проблемы. Например, открывая `http://localhost/auth/docs`, страница Swagger может не подгрузить спецификацию, т.к. она попытается обратиться к `/openapi.json` без префикса и Nginx не узнает, куда этот запрос направить. Чтобы Swagger работал: 
- **Вариант 1:** Явно указать префиксы в приложениях FastAPI. Например, при создании приложения `AuthService` использовать `app = FastAPI(title="Auth API", docs_url="/auth/docs", openapi_url="/auth/openapi.json")`. То есть, задать пути для документации с тем же префиксом, что и на gateway. Тогда `AuthService` будет ожидать, что его документация доступна по `/auth/docs` и спецификация по `/auth/openapi.json`. Аналогично для `LostFoundService`: `docs_url="/api/docs", openapi_url="/api/openapi.json"`. Этот подход информирует Swagger UI о правильных путях.  
- **Вариант 2:** Настроить правила в Nginx, чтобы перенаправлять запросы к `/auth/openapi.json` и `/api/openapi.json` правильно. В нашем примере, поскольку мы добавили слэш в `proxy_pass`, запрос к `/auth/openapi.json` должен автоматически отправиться в `auth_service` как `/openapi.json`. Если же это не сработает, можно добавить отдельные локации:
    ```nginx
    location /auth/openapi.json {
        proxy_pass http://auth_service:8000/openapi.json;
    }
    ```
  Но обычно, если `location /auth/` охватывает и этот путь, дополнительное правило не понадобится. Главное – **проверить, как Swagger UI запрашивает openapi.json**. В FastAPI Swagger UI по умолчанию использует относительный путь, поэтому с правильно настроенным `proxy_pass` все будет работать. Если нет, тогда используйте способ с `docs_url` и `openapi_url` или `root_path`.

Проверьте также, что **CORS** (Cross-Origin Resource Sharing) не блокирует запросы, если вы будете обращаться к сервисам с фронтенда напрямую. В случае gateway на том же домене проблем обычно нет, но если фронтенд хостится отдельно, нужно добавить middlewares CORSMiddleware в оба сервиса или настроить заголовки в Nginx.

После настройки Nginx все внешние запросы идут через него. Например:  
- `POST /auth/login` -> попадает на `AuthService` и возвращает JWT.  
- `GET /api/items` + заголовок `Authorization: Bearer <token>` -> попадает на `LostFoundService`, который проверяет JWT и возвращает данные.

Также можно открыть `http://localhost/api/docs` для просмотра Swagger UI основного сервиса и `http://localhost/auth/docs` для Swagger UI сервиса аутентификации, что удобно для тестирования отдельных сервисов.

## 6. Итоги и проверка работы  
После выполнения всех шагов у вас должна получиться архитектура из двух микросервисов с общим API Gateway. Подведем итог проделанной работы и рассмотрим, как убедиться, что система функционирует правильно.

**Запуск и тестирование.** Поднимите всю систему через Docker Compose: в терминале, находясь в директории с `docker-compose.yml`, выполните `docker-compose up --build`. Ключ `--build` соберет заново образы `AuthService` и `LostFoundService` с учетом изменений. Убедитесь, что все контейнеры стартовали без ошибок: вы должны увидеть логи от `auth_service`, `lostfound_service`, а также Nginx. 

Для проверки работоспособности: 
1. Зайдите на Swagger UI `AuthService`: откройте в браузере `http://localhost/auth/docs`. Должен отобразиться интерфейс Swagger с эндпоинтами аутентификации (например, `/auth/login`, `/auth/register`). Попробуйте через него зарегистрировать пользователя (если реализован `/auth/register`) или добавить тестового пользователя напрямую в базу данных. Затем выполните логин: отправьте запрос на `/auth/login` с корректными данными. В ответ вы должны получить JWT-токен. Скопируйте этот токен. 
2. Перейдите на Swagger UI основного сервиса: `http://localhost/api/docs`. Здесь будут эндпоинты для работы с объявлениями (например, создание новой находки, получение списка и т.д.). Нажмите кнопку "Authorize" в Swagger UI и введите полученный токен (тип **Bearer**). После авторизации попробуйте вызвать защищенные методы, например, создать новый элемент (`POST /api/items` или аналогичный эндпоинт) – запрос должен пройти, и сервис создаст запись, привязанную к вашему пользователю. Если попробовать выполнить этот же запрос **без** токена или с некорректным токеном, вы должны получить ошибку 401 Unauthorized. Это подтвердит, что защита JWT работает. 
3. Можно протестировать напрямую через `curl` или HTTP-клиент: 
   - `curl -X POST http://localhost/auth/login -d '{"username": "test", "password": "..."}' -H "Content-Type: application/json"` – получаем токен.
   - `curl -X GET http://localhost/api/items -H "Authorization: Bearer <TOKEN>"` – получаем данные (при валидном токене), либо ошибку (при неверном токене).

**Возможные проблемы и их решения:**  
- *Сервис не может подключиться к базе данных.* Проверьте переменные окружения в файлах `auth.env` и `lostfound.env`. Возможно, строка подключения (`database_url`) указана неправильно. В Docker Compose используйте имя хоста базы данных (например, `postgres://auth_user:auth_password@auth_db:5432/auth_db` для AuthService), т.е. указывайте имя контейнера базы как хост. Также убедитесь, что применены миграции Alembic: если таблицы не созданы, выполните миграции внутри контейнера (например, `docker-compose exec auth_service alembic upgrade head`). 
- *JWT-токен не проходит проверку на LostFoundService.* Убедитесь, что `SECRET_KEY` (или ключ) совпадает в настройках обоих сервисов. Если они разные, токен, подписанный AuthService, не валиден для LostFoundService. Это исправляется синхронизацией ключей (например, пропишите одинаковый секрет в `.env` обоих сервисов). Также проверьте, что алгоритм (HS256 и пр.) тот же. 
- *Nginx не направляет запросы правильно.* Если при обращении к `http://localhost/auth/login` вы получаете ошибку 404 от Nginx или одного из сервисов, проверьте конфигурацию `nginx.conf`. Возможно, префикс пути не совпадает. Убедитесь, что в `proxy_pass` используете синтаксис со слэшем в конце, чтобы пути правильно проксировались. Также загляните в логи контейнера Nginx (`docker-compose logs nginx`) – там может быть подсказка, на какой URL уходит запрос. 
- *Swagger UI не отображает схемы или выдает ошибку.* Если при открытии `/auth/docs` или `/api/docs` вы видите саму страницу, но она не может загрузить `/openapi.json`, это значит, что FastAPI не находит спецификацию. Решение – как описано выше: настроить `docs_url` и `openapi_url` при создании приложения FastAPI **или** поправить конфигурацию Nginx, чтобы запросы к `/auth/openapi.json` и т.п. доходили до сервисов. Один из способов – добавить `proxy_set_header Host $host;` (как мы сделали) и `proxy_set_header X-Forwarded-Prefix /auth` (иногда помогает, если использовать `root_path` в приложении). Для отладки можете открыть консоль разработчика в браузере на странице Swagger и посмотреть, куда пытается обратиться Swagger UI за JSON схемой. После корректировки путей проблема решится. 
- *Службы не запускаются или падают сразу при старте.* Посмотрите логи `auth_service` и `lostfound_service`. Часто причина – ошибка импорта (например, забыли обновить пути после рефакторинга), отсутствие нужной переменной окружения, или несоответствие схемы БД (например, `LostFoundService` пытается выполнить запрос к несуществующей таблице пользователей, если вы не удалили полностью старый код). Исправьте код согласно сообщениям об ошибке. Также убедитесь, что оба сервиса прослушивают правильный хост и порт (должен быть `0.0.0.0:8000` внутри контейнера, как указано в CMD uvicorn, чтобы Docker мог открыть порт). 

После устранения возможных проблем ваша система «монолит -> микросервисы» должна работать стабильно. Вы успешно разделили приложение на отдельные сервисы, настроили взаимодействие через API Gateway и обеспечили, что функциональность осталась прежней (пользователь может зарегистрироваться, залогиниться и выполнять операции с объявлениями, но теперь эти задачи обрабатывают разные сервисы). Эта пошаговая миграция на микросервисы продемонстрировала основные принципы: разделение ответственности, независимое развертывание, коммуникация через четкие интерфейсы (HTTP API) и использование общего gateway для внешнего мира.